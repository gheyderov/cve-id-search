I learned how to use Selenium, Requests, and BeautifulSoup. My task was to scrape specific data from ExploitDB and NIST. Here's how I did it: I used combinations of libraries to scrape data and extract only the necessary information from them, such as Requests + BeautifulSoup. Specifically, I scraped exploit links from ExploitDB and extracted affected software information from NIST. Additionally, I created a function for scraping data and shared it with my team members. We tested the functions together with Gunduz and improved their usability for our project. Now, whenever a CVE ID is entered on our project's frontend, it triggers my function automatically. This function then proceeds to scrape the relevant data and generates a specific output tailored for the creation of a table in a PDF format.